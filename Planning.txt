Tâches effectuées :
->Algorithme 0. Fonction Valeur qui calcul la valeur d'une politique + exemple du taxi (Fait le jour1/2)
->Algorithme 1. Fonction qui détermine la politique espilon-optimale d'un environnement en utilisant l'équation de Bellman + exemple du taxi (Fait le jour 2/3)
->Preuve du nombre de politique possible pour un environnement à E états et A actions possiblse(Fait le jour 3)
->Faire un dépôt GIT (Fait jour3)
->Algorithme 2. Fonction qui détermine la politique espilon-optimale d'un environnement en utilisant l'équation d'optimalité de Bellman + exemple du taxi (Fait jour4)
->Début du document de présentation en Latex (Fait jour4)

-> Week-end (J-5/6)

->Algorithme 3. Fonction qui permet de se rapprocher de la valeur optimale sans connaitre les fonctions de transition ni de retour. (Fait le jour 7/8)
Cet algorithme me semble pas correct dû a son cout même si un critère d'arrêt est que chaque état soit visité une infinité de fois (à retravailler)

->Programme qui affiche les valeurs possibles de toutes les politiques stationnaires et déterministes possibles du problème du chauffeur de taxi, pour gamma= 0,9. (Fait jour 8)

->Algorithme 4 : Q-learning. (Fait le jour 9/10/11)

->Semaine 3:
	->Etude de la fonction qualité dans environnement autre que celui dans le quel elle a été entrainée
	->Etude de l'algorithme de Q-Learning dans un environnement évolutif
	->Rédaction des idées d'amélioration de l'algorithme de Q-Learning (tau qui croit et décroit)
	->Etude de la compléxité des algorithmes
	->Rédaction de tout ça sur le fichier Latex


->Semaine4:
	->Remise au propre du code
	->Detection d'un gros problème de code (oublie de faire n(st,at) = n(st,at) +1) /!\Est-ce un PB ? 
	->Sarsa (seulement pour Boltzmann pour l'instant, pour Eps-Gloutonne arrive)
	->Q(Lambda) (avec Boltzmann)

->Semaine 5:
	->Derniers algorithmes
	->Rédaction final du compte rendu