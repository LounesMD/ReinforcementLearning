Tâches effectuées :
->Algorithme 0. Fonction Valeur qui calcul la valeur d'une politique + exemple du taxi (Fait le jour1/2)
->Algorithme 1. Fonction qui détermine la politique espilon-optimale d'un environnement en utilisant l'équation de Bellman + exemple du taxi (Fait le jour 2/3)
->Preuve du nombre de politique possible pour un environnement à E états et A actions possiblse(Fait le jour 3)
->Faire un dépôt GIT (Fait jour3)
->Algorithme 2. Fonction qui détermine la politique espilon-optimale d'un environnement en utilisant l'équation d'optimalité de Bellman + exemple du taxi (Fait jour4)
->Début du document de présentation en Latex (Fait jour4)

-> Week-end (J-5/6)

->Algorithme 3. Fonction qui permet de se rapprocher de la valeur optimale sans connaitre les fonctions de transition ni de retour. (Fait le jour 7/8)
Cet algorithme me semble pas correct dû a son cout même si un critère d'arrêt est que chaque état soit visité une infinité de fois
->Programme qui affiche les valeurs possibles de toutes les politiques stationnaires et déterministes possibles du problème du chauffeur de taxi, pour gamma= 0,9. (Fait jour 8)

A venir:
->Document Latex de présentation du projet (régulièrement fait)

->Algorithme 3. Différence temporelle, algorithme TD pour une politique déterministe (et stationnaire) (à retravailler pour la vérification des résultats)

->Algorithme 4. Algorithme de Q-learning
	->L'implémenter pour un labyrinthe
	->Trouver d'autres possibilités (Mario ?)
	->Tracer la courbre d'apprentissage

->Algorithme 5. Algorithme SARSA
->Algorithme 6. Algorithme Q(lambda)
->Algorithme 7. ALgorithme Monte Carlo 

	-> Faire une étude de l'éfficacité de chacun de ces algorithmes

->Application du Q-learning pour le cas de la voiture-dans-la-colline

->Etude de la compléxité de chacun des algorithmes
